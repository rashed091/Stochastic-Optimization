{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div id=\"introduction-to-pyro\" class=\"section level2\">\n",
    "<h2><span class=\"header-section-number\">4.2</span> Introduction to Pyro</h2>\n",
    "<p>Pyro is a universal probabilistic programming language (PPL) written in Python and supported by PyTorch on the backend. Pyro enables flexible and expressive deep probabilistic modeling, unifying the best of modern deep learning and Bayesian modeling.</p>\n",
    "<p>Our purpose of this class, pyro has “do”-operator that allows intervention and counterfactual inference in these probabilistic models.</p>\n",
    "<div id=\"stochastic-functions\" class=\"section level3\">\n",
    "<h3><span class=\"header-section-number\">4.2.1</span> Stochastic Functions</h3>\n",
    "<p>The basic unit of probabilistic programs is the stochastic function. A stochastic function is an arbitrary Python callable that combines two ingredients:</p>\n",
    "<ul>\n",
    "<li>deterministic Python code; and</li>\n",
    "<li>primitive stochastic functions that call a random number generator</li>\n",
    "</ul>\n",
    "<p>For this course, we will consider these stochastic functions as <strong>models</strong>. Stochastic functions can be used to represent simplified or abstract descriptions of a data-generating process.</p>\n",
    "</div>\n",
    "<div id=\"primitive-stochastic-functions\" class=\"section level3\">\n",
    "<h3><span class=\"header-section-number\">4.2.2</span> Primitive stochastic functions</h3>\n",
    "<p>We call them distributions. We can explicitly compute the probability of the outputs given the inputs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:  tensor(-1.3905)\n"
     ]
    }
   ],
   "source": [
    "loc = 0.   # mean zero\n",
    "scale = 1. # unit variance\n",
    "normal = torch.distributions.Normal(loc, scale) # create a normal distribution object\n",
    "x = normal.rsample() # draw a sample from N(0,1)\n",
    "print(\"sample: \", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyro simplifies this process of sampling from distributions. It uses pyro.sample()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8152)\n"
     ]
    }
   ],
   "source": [
    "x = pyro.sample(\"my_sample\", pyro.distributions.Normal(loc, scale))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Just like a direct call to <code>torch.distributions.Normal().rsample()</code>, this returns a sample from the unit normal distribution. The crucial difference is that this sample is named. Pyro’s backend uses these names to uniquely identify sample statements and change their behavior at runtime depending on how the enclosing stochastic function is being used. This is how Pyro can implement the various manipulations that underlie inference algorithms.</p>\n",
    "<p>Let’s write a simple <code>weather</code> model.</p>\n",
    "\n",
    "<h3><span class=\"header-section-number\">4.2.3</span> A simple model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cloudy', 51.373016357421875)\n",
      "('cloudy', 52.28388595581055)\n",
      "('sunny', 70.28937530517578)\n"
     ]
    }
   ],
   "source": [
    "def weather():\n",
    "    cloudy = pyro.sample('cloudy', dist.Bernoulli(0.3))\n",
    "    cloudy = 'cloudy' if cloudy.item() == 1.0 else 'sunny'\n",
    "    mean_temp = {'cloudy': 55.0, 'sunny': 75.0}[cloudy]\n",
    "    scale_temp = {'cloudy': 10.0, 'sunny': 15.0}[cloudy]\n",
    "    temp = pyro.sample('temp', dist.Normal(mean_temp, scale_temp))\n",
    "    return cloudy, temp.item()\n",
    "for _ in range(3):\n",
    "    print(weather())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First two lines introduce a binary variable <code>cloudy</code>, which is given by a draw from the Bernoulli distribution with a parameter of <span class=\"math inline\">\\(0.3\\)</span>. The Bernoulli distribution returns either <span class=\"math inline\">\\(0\\)</span> or <span class=\"math inline\">\\(1\\)</span>, line <code>2</code> converts that into a string. So, So according to this model, <span class=\"math inline\">\\(30%\\)</span> of the time it’s cloudy and <span class=\"math inline\">\\(70%\\)</span> of the time it’s sunny.</p>\n",
    "<p>In line <code>4</code> and <code>5</code>, we initialize mean and scale of the temperature for both values. We then sample, the temperature from a Normal distribution and return that along with <code>cloudy</code> variable.</p>\n",
    "<p>We can build complex model by modularizing and reusing the concepts into functions and use them as programmers use functions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ice_cream_sales():\n",
    "    cloudy, temp = weather()\n",
    "    expected_sales = 200. if cloudy == 'sunny' and temp > 80.0 else 50.\n",
    "    ice_cream = pyro.sample('ice_cream', pyro.distributions.Normal(expected_sales, 10.0))\n",
    "    return ice_cream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span class=\"header-section-number\">4.3</span> Inference</h2>\n",
    "<p>As we discussed earlier, the reason we use PPLs is because they can easily go backwards and reason about cause given the observed effect. There are myriad of inference algorithms available in pyro. Let’s try it on an even simpler model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9213)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale(guess):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "    measurement = pyro.sample(\"measurement\", dist.Normal(weight, 0.75))\n",
    "    return measurement\n",
    "scale(5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Suppose we observe that the <code>measurement</code> of an object was <span class=\"math inline\">\\(14\\)</span> lbs. What would have we guessed if we tried to guess it’s <code>weight</code> first?</p>\n",
    "<p>This question is answered in two steps.</p>\n",
    "<ol style=\"list-style-type: decimal\">\n",
    "<li>Condition the model.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned_scale = pyro.condition(scale, data={\"measurement\": torch.tensor(14.)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"2\" style=\"list-style-type: decimal\">\n",
    "<li>Set the prior and infer the posterior. We will use</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1050/1050 [00:04<00:00, 262.34it/s, step size=1.31e+00, acc. rate=0.930]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.mcmc import MCMC\n",
    "from pyro.infer.mcmc.nuts import HMC\n",
    "from pyro.infer import EmpiricalMarginal\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "guess_prior = 10.\n",
    "hmc_kernel = HMC(conditioned_scale, step_size=0.9, num_steps=4)\n",
    "posterior = MCMC(hmc_kernel, num_samples=1000, warmup_steps=50).run(guess_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '#')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "marginal = EmpiricalMarginal(posterior, \"weight\")\n",
    "plt.hist([marginal().item() for _ in range(1000)],)\n",
    "plt.title(\"P(weight | measurement = 14)\")\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span class=\"header-section-number\">4.3.0.1</span> Shapes in distribution:</h4>\n",
    "<p>We know that PyTorch tensor have single <code>shape</code> attribute, <code>Distribution</code>s have two shape attributes with special meaning. * <code>.batch_shape</code>: Indices over <code>.batch_shape</code> denote conditionally independent random variables, * <code>.event_shape</code>: indices over <code>.event_shape</code> denote dependent random variables (ie one draw from a distribution).</p>\n",
    "<p>These two combine to define the total shape of a sample. Thus the total shape of <code>.log_prob()</code> of distribution is <code>.batch_shape</code>.</p>\n",
    "<p>Also, <code>Distribution.sample()</code> also has a <code>sample_shape</code> attribute that indexes over independent and identically distributed(iid) random variables.</p>\n",
    "\n",
    "\n",
    "<pre><code>      |      iid     | independent | dependent\n",
    "------+--------------+-------------+------------\n",
    "shape = sample_shape + batch_shape + event_shape</code></pre>\n",
    "<p>To know more about + , go through <a href=\"https://pytorch.org/docs/master/notes/broadcasting.html\">broadcasting tensors in PyTorch</a>.</p>\n",
    "\n",
    "<h3><span class=\"header-section-number\">4.3.1</span> Examples</h3>\n",
    "<p>One way to introduce batch_shape is use <code>expand</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_shape:  torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "d = dist.MultivariateNormal(torch.zeros(3), torch.eye(3, 3)).expand([5]) # expand - 3 of these Multivariate Normal Dists\n",
    "print(\"batch_shape: \", d.batch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_shape:  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(\"event_shape: \", d.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = d.sample()\n",
    "print(\"x shape: \", x.shape)          # == sample_shape + batch_shape + event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.log_prob(x) shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(\"d.log_prob(x) shape:\", d.log_prob(x).shape)  # == batch_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The other way is using <code>plate</code> context manager.</p>\n",
    "<p>Pyro models can use the context manager <code>pyro.plate</code> to declare that certain batch dimensions are independent. Inference algorithms can then take advantage of this independence to e.g. construct lower variance gradient estimators or to enumerate in linear space rather than exponential space.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pyro.plate(\"x_axis\", 5):\n",
    "    d = dist.MultivariateNormal(torch.zeros(3), torch.eye(3, 3))\n",
    "    x = pyro.sample(\"x\", d)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In fact, we can also nest <code>plates</code>. The only thing we need to care about is, which dimensions are independent. Pyro automatically manages this but sometimes we need to explicitely specify the dimensions. Once we specify that, we can leverage PyTorch’s CUDA enabled capabilities to run inference on GPUs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-17-c756cd874096>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-c756cd874096>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    # within this context, batch dimensions -2 and -1 are independent\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with pyro.plate(\"x_axis\", 320):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "    with pyro.plate(\"y_axis\", 200):\n",
    "        # within this context, batch dimensions -2 and -1 are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that we always count from the right by using negative indices like <span class=\"math inline\">\\(-2\\)</span>, <span class=\"math inline\">\\(-1\\)</span>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

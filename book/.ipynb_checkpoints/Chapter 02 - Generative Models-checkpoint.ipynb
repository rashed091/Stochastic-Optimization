{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Generative Models\n",
    "\n",
    "We wish to describe in formal terms how to generate states of the world.\n",
    "That is, we wish to describe the causal process, or steps that unfold, leading to some potentially observable states.\n",
    "The key idea of this section is that these generative processes can be described as *computations*---computations that involve random choices to capture uncertainty about the process.\n",
    "\n",
    "Programming languages are formal systems for describing what (deterministic) computation a computer should do. Modern programming languages offer a wide variety of different ways to describe computation; each makes some processes simple to describe and others more complex. However, a key tenet of computer science is that all of these languages have the same fundamental power: any computation that can be described with one programming language can described by another. (More technically this Church-Turing thesis posits that many specific computational systems capture the set of all effectively computable procedure. These are called *universal* systems.)\n",
    "\n",
    "For example, the `flip` function can be thought of as simulating a (possibly biased) coin toss (technically `flip` samples from a Bernoulli distribution, which we'll return to shortly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this program a few times.\n",
    "You will get back a different sample on each execution.\n",
    "Also, notice the parentheses after `flip`.\n",
    "These are meaningful; they tell WebPPL that you are calling the `flip` function---resulting in a sample.\n",
    "Without parentheses `flip` is a *function* object---a representation of the simulator itself, which can be used to get samples.\n",
    "\n",
    "In WebPPL, each time you run a program you get a *sample* by simulating the computations and random choices that the program specifies.\n",
    "If you run the program many times, and collect the values in a histogram, you can see what a typical sample looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used the `repeat` procedure which takes a number of repetitions, $K$, and a function (in this case `flip`) and returns a list of $K$ samples from that function.\n",
    "We have used the `viz` function to visualize the results of calling the `flip` function 1000 times.\n",
    "As you can see, the result is an approximately uniform distribution over `true` and `false`.\n",
    "\n",
    "Using `flip` we can construct more complex expressions that describe more complicated sampling processes. For instance here we describe a process that samples a number adding up several flips (note that in JavaScript a boolean will be turned into a number, $0$ or $1$, by the plus operator `+`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to invoke this sampling process multiple times? We would like to construct a stochastic function that adds three random numbers each time it is called.\n",
    "We can use `function` to construct such complex stochastic functions from the primitive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Flipping Coins\n",
    "\n",
    "The following program defines a fair coin, and flips it 20 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program defines a \"trick\" coin that comes up heads most of the time (95%), and flips it 20 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand how the `bend` function works! Why are there an \"extra\" pair of parentheses after each `make-coin` statement?\n",
    "\n",
    "Higher-order functions like `repeat`, `map`, and `apply` can be quite useful.\n",
    "Here we use them to visualize the number of heads we expect to see if we flip a weighted coin (weight = 0.8) 10 times.\n",
    "We'll repeat this experiment 1000 times and then use `viz` to visualize the results.\n",
    "Try varying the coin weight or the number of repetitions to see how the expected distribution changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Causal Models in Medical Diagnosis\n",
    "\n",
    "Generative knowledge is often *causal* knowledge that describes how events or states of the world are related to each other.\n",
    "As an example of how causal knowledge can be encoded in WebPPL expressions, consider a simplified medical scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program models the diseases and symptoms of a patient in a doctor's office.\n",
    "It first specifies the base rates of two diseases the patient could have: lung cancer is rare while a cold is common, and there is an independent chance of having each disease.\n",
    "The program then specifies a process for generating a common symptom of these diseases -- an effect with two possible causes: The patient coughs if they have a cold or lung cancer (or both).\n",
    "\n",
    "Here is a more complex version of this causal model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are four possible diseases and four symptoms.\n",
    "Each disease causes a different pattern of symptoms.\n",
    "The causal relations are now probabilistic: Only some patients with a cold have a cough (50%), or a fever (30%).\n",
    "There is also a catch-all disease category \"other\", which has a low probability of causing any symptom.\n",
    "*Noisy logical* functions---functions built from **and** (`&&`), **or** (`||`), and `flip`---provide a simple but expressive way to describe probabilistic causal dependencies between Boolean (true-false valued) variables.\n",
    "\n",
    "When you run the above code, the program generates a list of symptoms for a hypothetical patient.\n",
    "Most likely all the symptoms will be false, as (thankfully) each of these diseases is rare.\n",
    "Experiment with running the program multiple times.\n",
    "Now try modifying the `var` statement for one of the diseases, setting it to be true, to simulate only patients known to have that disease.\n",
    "For example, replace `var lungCancer = flip(0.01)` with `var lungCancer = true`.\n",
    "Run the program several times to observe the characteristic patterns of symptoms for that disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prediction, Simulation, and Probabilities\n",
    "\n",
    "Suppose that we flip two fair coins, and return the list of their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we predict the return value of this program?\n",
    "For instance, how likely is it that we will see `[true, false]`?\n",
    "A **probability** is a number between 0 and 1 that expresses the answer to such a question: it is a degree of belief that we will see a given outcome, such as `[true, false]`.\n",
    "The probability of an event $$A$$ (such as the above program returning `[true, false]`) is usually written as: $$P(A)$$.\n",
    "\n",
    "A **probability distribution** is the probability of each possible outcome of an event. For instance, we can examine the probability distribution on values that can be returned by the above program by sampling many times and examining the histogram of return values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see by examining this histogram that `[true, false]` comes out about 25% of the time.\n",
    "We may define the probability of a return value to be the fraction of times (in the long run) that this value is returned from evaluating the program -- then the probability of `[true, false]` from the above program is 0.25.\n",
    "\n",
    "## Distributions in WebPPL\n",
    "\n",
    "An important idea is that `flip` can be thought of in two different ways.\n",
    "From one perspective, `flip` is a procedure which returns a sample from a fair coin.\n",
    "That is, it's a *sampler* or *simulator*. As we saw above we can build more complex samplers by building more complex functions.\n",
    "From another perspective, `flip` is *itself* a characterization of the probability distribution over `true` and `false`.\n",
    "In order to make this view explicit, WebPPL has a special type of **distribution** objects. These are objects that can be sampled from using the `sample` operator, and that can explicitly return the probability of a return value using the `score` method. Distributions are made by a family of distribution constructors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact `flip(x)` is just a helper function that constructs a Bernoulli distribution and samples from it. The function `bernoulli(x)` is an alias for `flip`.\n",
    "There are many other distribution constructors built into WebPPL listed [here](http://docs.webppl.org/en/master/distributions.html) (and each has a sampling helper, named in lower case). For instance the Gaussian (also called Normal) distribution is a very common distribution over real numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing marginal distributions: `Infer`\n",
    "\n",
    "Above we described how complex sampling processes can be built as complex functions, and how these sampling processes implicitly specify a distribution on return values (which we examined by sampling many times and building a histogram). This distribution on return values is called the **marginal distribution**, and the WebPPL `Infer` operator gives us a way to make this implicit distribution into an explicit distribution object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `Infer` took an object describing *how* to construct the marginal distribution (which we will describe more later) and a thunk describing the sampling process, or *model*, of interest. For more details see the [Infer documentation](http://docs.webppl.org/en/master/inference/index.html).\n",
    "\n",
    "Thus `sample` lets us sample from a distribution, and build complex sampling processes by using sampling in a program; conversely, `Infer` lets us reify the distribution implicitly described by a sampling process.\n",
    "When we think about probabilistic programs we will often move back and forth between these two views, emphasizing either the sampling perspective or the distributional perspective.\n",
    "With suitable restrictions this duality is complete: any WebPPL program implicitly represents a distribution and any distribution can be represented by a WebPPL program; see e.g., @Ackerman2011 for more details on this duality.\n",
    "\n",
    "\n",
    "# The rules of probability\n",
    "\n",
    "While `Infer` lets us build the marginal distribution for even very complicated programs, we can also derive these marginal distributions with the \"rules of probability\". This is intractable for complex processes, but can help us build intuition for how distributions work.\n",
    "\n",
    "## Product Rule\n",
    "\n",
    "In the above example we take three steps to compute the output value: we sample from the first `flip()`, then from the second, then we make a list from these values.\n",
    "To make this more clear let us re-write the program as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly observe (as we did above) that the probability of `true` for `A` is 0.5, and the probability of `false` from `B` is 0.5. Can we use these two probabilities to arrive at the probability of 0.25 for the overall outcome `C` = `[true, false]`? Yes, using the *product rule* of probabilities:\n",
    "The probability of two random choices is the product of their individual probabilities.\n",
    "The probability of several random choices together is often called the *joint probability* and written as $$P(A,B)$$.\n",
    "Since the first and second random choices must each have their specified values in order to get `[true, false]` in the example, the joint probability is their product: 0.25.\n",
    "\n",
    "We must be careful when applying this rule, since the probability of a choice can depend on the probabilities of previous choices. For instance, compute the probability of `[true, false]` resulting from this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the joint probability of two random choices $$A$$ and $$B$$ made sequentially, in that order, can be written as $$P(A,B) = P(A) P(B \\vert A)$$.\n",
    "This is read as the product of the probability of $$A$$ and the probability of \"$$B$$ given $$A$$\", or \"$$B$$ conditioned on $$A$$\".\n",
    "That is, the probability of making choice $$B$$ given that choice $$A$$ has been made in a certain way.\n",
    "Only when the second choice does not depend on (or \"look at\") the first choice does this expression reduce to a simple product of the probabilities of each choice individually: $$P(A,B) = P(A) P(B)$$.\n",
    "\n",
    "What is the relation between $$P(A,B)$$ and $$P(B,A)$$, the joint probability of the same choices written in the opposite order?  The only logically consistent definitions of probability require that these two probabilities be equal, so $$P(A) P(B \\vert A) = P(B) P(A \\vert B)$$.  This is the basis of *Bayes' theorem*, which we will encounter later.\n",
    "\n",
    "## Sum Rule\n",
    "\n",
    "Now let's consider an example where we can't determine from the overall return value the sequence of random choices that were made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample from this program and determine that the probability of returning `true` is about 0.75.\n",
    "\n",
    "We cannot simply use the product rule to determine this probability because we don't know the sequence of random choices that led to this return value.\n",
    "However we can notice that the program will return true if the two component choices are `[true,true]`, or `[true,false]`, or `[false,true]`. To combine these possibilities we use another rule for probabilities:\n",
    "If there are two alternative sequences of choices that lead to the same return value, the probability of this return value is the sum of the probabilities of the sequences.\n",
    "We can write this using probability notation as: $$P(A) = \\sum_{B} P(A,B)$$, where we view $$A$$ as the final value and $$B$$ as a random choice on the way to that value.\n",
    "Using the product rule we can determine that the probability in the example above is 0.25 for each sequence that leads to return value `true`, then, by the sum rule, the probability of `true` is 0.25+0.25+0.25=0.75.\n",
    "\n",
    "Using the sum rule to compute the probability of a final value is called is sometimes called *marginalization*, because the final distribution is the marginal distribution on final values.\n",
    "From the point of view of sampling processes marginalization is simply ignoring (or not looking at) intermediate random values that are created on the way to a final return value.\n",
    "From the point of view of directly computing probabilities, marginalization is summing over all the possible \"histories\" that could lead to a return value.\n",
    "Putting the product and sum rules together, the marginal probability of return values from a program that we have explored above is the sum over sampling histories of the product over choice probabilities---a computation that can quickly grow unmanageable, but can be approximated by `Infer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic recursion\n",
    "\n",
    "[Recursive functions](https://en.wikipedia.org/wiki/Recursion_(computer_science)) are a powerful way to structure computation in deterministic systems.\n",
    "In WebPPL it is possible to have a *stochastic* recursion that randomly decides whether to stop.\n",
    "For example, the *geometric distribution* is a probability distribution over the non-negative integers.\n",
    "We imagine flipping a (weighted) coin, returning $$N-1$$ if the first `true` is on the Nth flip (that is, we return the number of times we get `false` before our first `true`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Intuitive physics\n",
    "\n",
    "Humans have a deep intuitive understanding of everyday physics---this allows us to make furniture, appreciate sculpture, and play baseball.\n",
    "How can we describe this intuitive physics? One approach is to posit that humans have a generative model that captures key aspects of real physics, though perhaps with approximations and noise.\n",
    "This mental physics simulator could for instance approximate Newtonian mechanics, allowing us to imagine the future state of a collection of (rigid) bodies.\n",
    "We have included such a 2-dimensional physics simulator, the function `runPhysics`, that takes a collection of physical objects and runs physics 'forward' by some amount of time.\n",
    "(We also have `animatePhysics`, which does the same, but gives us an animation to see what is happening.)\n",
    "We can use this to imagine the outcome of various initial states, as in the Plinko machine example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
